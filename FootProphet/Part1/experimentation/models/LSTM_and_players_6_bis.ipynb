{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "pd.options.display.max_columns=None\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_metrics(true_label,pred_label, labels_):\n",
    "  cm = confusion_matrix(true_label,pred_label,labels = labels_)\n",
    "  cmDisp = ConfusionMatrixDisplay(cm,display_labels=labels_)\n",
    "  recall = { i:cm[i][i]/cm[i].sum()  for i in range(len(cm))}\n",
    "  precision = { i:cm[i][i]/cm[:,i].sum()  for i in range(len(cm))}\n",
    "  F1_score = { i: 2 / (1/recall[i] + 1/precision[i]) for i in range(len(cm))}\n",
    "  accuracy = (cm[0][0]+cm[1][1]+cm[2][2])/cm.sum()\n",
    "  print('accuracy: ', accuracy)\n",
    "  print('Recall: \\n',recall,'\\nPrecision: \\n', precision,'\\nF1-score: \\n',F1_score)\n",
    "  cmDisp.plot()\n",
    "  plt.show()\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_history = pd.read_csv('../data/train_LSTM/home_history_full.csv', index_col = 0,\\\n",
    "    dtype={'home_id' : np.int32, 'game_id' : np.int32, 'H_goals' : np.int8, 'H_goals_conceded' : np.int8,\\\n",
    "         'H_HorA' : np.int8, 'H_yellow_cards' : np.int8, 'H_red_cards' : np.int8}\\\n",
    "    )\n",
    "\n",
    "away_history = pd.read_csv('../data/train_LSTM/away_history_full.csv', index_col = 0,\\\n",
    "    dtype={'away_id' : np.int32, 'game_id' : np.int32, 'A_goals' : np.int8, 'A_goals_conceded' : np.int8,\\\n",
    "         'A_HorA' : np.int8, 'A_yellow_cards' : np.int8, 'A_red_cards' : np.int8}\\\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_history = pd.read_csv('../data/train_LSTM/game_history_full.csv', index_col = 0,\\\n",
    "    dtype={'game_history_id' : np.int32, 'game_id' : np.int32, 'H_goals' : np.int8, 'H_goals_conceded' : np.int8,\\\n",
    "         'H_HorA' : np.int8, 'H_yellow_cards' : np.int8, 'H_red_cards' : np.int8, 'A_yellow_cards' : np.int8, 'A_red_cards' : np.int8}\\\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/training_data/train_final_6_bis.csv', index_col = 0)\n",
    "#train_df = train_df.astype(dtype={x:np.float32 for x in train_df.columns[1:-1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_best = pd.read_csv( '../data/training_data/train_best_final_6.csv', index_col = 0)\n",
    "train_best = train_best.astype(dtype={x:np.float16 for x in train_best.columns[1:]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selection des matchs dans game_history, away_history et game_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# on rajoute des 0 et des 1 au début de chaque ligne pour indiquer si il y a un match ou pas\n",
    "# on inverse le game_history avec np.flip(game_history,axis=1) pour classer les matches du plus ancien au plus récent\n",
    "# Cela dit l'expérience montre que cette inversion n'a pas énormément d'impact sur les performances du modèle... \n",
    "\n",
    "def make_home_train(game_id):\n",
    "    game_history = home_history.loc[home_history.game_id == game_id,:].drop(columns=['home_id','game_id'])\n",
    "    if (n_lines := game_history.shape[0]) == 0:\n",
    "        return np.zeros((10,6)).astype(np.int8)\n",
    "    else:\n",
    "        return np.vstack(( np.zeros((10-n_lines,6)) , np.hstack(( np.ones((n_lines,1)) , np.flip(game_history.to_numpy(),axis=1))) )).astype(np.int8)\n",
    "\n",
    "def make_away_train(game_id):\n",
    "    game_history = away_history.loc[away_history.game_id == game_id,:].drop(columns=['away_id','game_id'])\n",
    "    if (n_lines := game_history.shape[0]) == 0:\n",
    "        return np.zeros((10,6)).astype(np.int8)\n",
    "    else:\n",
    "        return np.vstack(( np.zeros((10-n_lines,6)) , np.hstack(( np.ones((n_lines,1)) , np.flip(game_history.to_numpy(),axis=1))) )).astype(np.int8)\n",
    "\n",
    "# on rajoute des 0 et des 1 au début de chaque ligne pour indiquer si il y a un match ou pas\n",
    "# on inverse le game_history avec np.flip(game_history,axis=1) pour classer les matches du plus ancien au plus récent\n",
    "# Cela dit l'expérience montre que cette inversion n'a pas énormément d'impact sur les performances du modèle... \n",
    "\n",
    "def make_history_train(game_id):\n",
    "    encounter_history = game_history.loc[game_history.game_id == game_id,:].drop(columns=['game_history_id','game_id'])\n",
    "    if (n_lines := encounter_history.shape[0]) == 0:\n",
    "        return np.zeros((5,8)).astype(np.int8)\n",
    "    else:\n",
    "        return np.vstack(( np.zeros((5-n_lines,8)) , np.hstack(( np.ones((n_lines,1)) , np.flip(encounter_history.to_numpy(),axis=1))) )).astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATTENTION: certaines parties apparaissent en double dans games.csv\n",
    "tt = home_history.groupby('game_id')['home_id'].count().reset_index()\n",
    "display(tt.loc[tt.home_id>10,:])\n",
    "# ça nous casse les pieds on va s'en débarasser, il n'y en a que trois, on les jarte\n",
    "home_history.drop(home_history.loc[home_history.game_id.isin( tt.loc[tt.home_id>10,'game_id'] ), :].index,inplace = True)\n",
    "\n",
    "\n",
    "#idem pour away_history\n",
    "\n",
    "tt = away_history.groupby('game_id')['away_id'].count().reset_index()\n",
    "display(tt.loc[tt.away_id>10,:])\n",
    "away_history.drop(away_history.loc[away_history.game_id.isin( tt.loc[tt.away_id>10,'game_id'] ), :].index,inplace = True)\n",
    "\n",
    "#idem pour game_history?\n",
    "\n",
    "tt = game_history.groupby('game_id')['game_history_id'].count().reset_index()\n",
    "display(tt.loc[tt.game_history_id>5,:])\n",
    "game_history.drop(game_history.loc[game_history.game_id.isin( tt.loc[tt.game_history_id>5,'game_id'] ), :].index,inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_ids = train_df.game_id.astype(np.int32)\n",
    "\n",
    "train_home = game_ids.progress_apply(make_home_train)\n",
    "train_home = np.stack(train_home.values)\n",
    "\n",
    "train_away = game_ids.progress_apply(make_away_train)\n",
    "train_away = np.stack(train_away.values)\n",
    "\n",
    "train_history = game_ids.progress_apply(make_history_train)\n",
    "train_history = np.stack(train_history.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_home.shape, train_away.shape, train_history.shape, train_best.shape, train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.Home_result = train_df.Home_result.apply(lambda x: \\\n",
    "    0 if x>0 else( 1 if x==0 else 2 )\\\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = [x+y for x in ['H_', 'A_'] for y in ['GK', 'attack', 'defense', 'midfield']]\n",
    "col_list = col_list + ['game_id', 'Home_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[:, [x for x in train_df.columns if x not in col_list]]=train_df.loc[:, [x for x in train_df.columns if x not in col_list]]/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_best.loc[:, train_best.columns[1:]] = train_best.loc[:, train_best.columns[1:]]/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## préparons les données pour l'entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_home = train_home.astype(np.float16)\n",
    "train_away = train_away.astype(np.float16)\n",
    "train_history = train_history.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df.Home_result.values\n",
    "best_players = train_best.drop(columns=['game_id']).to_numpy()\n",
    "players = train_df.drop(columns = ['game_id', 'Home_result']).to_numpy()\n",
    "XH_train, XH_test, XA_train, XA_test, XG_train, XG_test, best_train, best_test, players_train, players_test, y_train, y_test = \\\n",
    "    train_test_split(train_home, train_away, train_history, best_players, players, y, test_size = 0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "  def __init__(self, xh_data, xa_data, xg_data, xbest_data, xplayer_data, y_data, batch_size):\n",
    "    self.xh,self.xa, self.xg, self.xbest, self.xplayers, self.y = \\\n",
    "        xh_data, xa_data, xg_data, xbest_data, xplayer_data, y_data\n",
    "    self.batch_size = batch_size\n",
    "    self.num_batches = np.ceil(len(xh_data) / batch_size)\n",
    "    self.batch_idx = np.array_split(range(len(xh_data)), self.num_batches)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.batch_idx)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    batch_xh = self.xh[self.batch_idx[idx]]\n",
    "    batch_xa = self.xa[self.batch_idx[idx]]\n",
    "    batch_xg = self.xg[self.batch_idx[idx]]\n",
    "    batch_xbest = self.xbest[self.batch_idx[idx]]\n",
    "    batch_xplayers = self.xplayers[self.batch_idx[idx]]\n",
    "    batch_y = self.y[self.batch_idx[idx]]\n",
    "    return [batch_xh, batch_xa, batch_xg, batch_xplayers, batch_xbest], batch_y\n",
    "\n",
    "train_generator = DataGenerator(XH_train, XA_train, XG_train, best_train, players_train, y_train, batch_size = 128)\n",
    "val_generator =   DataGenerator(XH_test,  XA_test,  XG_test,  best_test,  players_test,  y_test,  batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator2(tf.keras.utils.Sequence):\n",
    "  def __init__(self, xh_data, xa_data, xg_data, xplayer_data, y_data, batch_size):\n",
    "    self.xh,self.xa, self.xg, self.xplayers, self.y = \\\n",
    "        xh_data, xa_data, xg_data, xplayer_data, y_data\n",
    "    self.batch_size = batch_size\n",
    "    self.num_batches = np.ceil(len(xh_data) / batch_size)\n",
    "    self.batch_idx = np.array_split(range(len(xh_data)), self.num_batches)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.batch_idx)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    batch_xh = self.xh[self.batch_idx[idx]].astype(np.float32)\n",
    "    batch_xa = self.xa[self.batch_idx[idx]].astype(np.float32)\n",
    "    batch_xg = self.xg[self.batch_idx[idx]].astype(np.float32)\n",
    "    batch_xplayers = self.xplayers[self.batch_idx[idx]].astype(np.float32)\n",
    "    batch_y = self.y[self.batch_idx[idx]].astype(np.float32)\n",
    "    return [batch_xh, batch_xa, batch_xg, batch_xplayers], batch_y\n",
    "\n",
    "train_generator2 = DataGenerator2(XH_train, XA_train, XG_train, players_train, y_train, batch_size = 128)\n",
    "val_generator2 =   DataGenerator2(XH_test,  XA_test,  XG_test,  players_test,  y_test,  batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import L1L2\n",
    "LSTM_model = tf.keras.models.load_model('../data/models/H_A_game_history_LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_generator2))[0][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "home_input = tf.keras.Input(shape = (10,6) , name = 'home_train_input')                                   #input 1\n",
    "home_LSTM_1 = tf.keras.layers.LSTM(32, kernel_regularizer = L1L2(l1=0.01, l2=0.01), name = 'home_LSTM_1')(home_input)\n",
    "\n",
    "away_input = tf.keras.Input(shape = (10,6), name = 'away_train_input')                                   #input 2\n",
    "away_LSTM_1 = tf.keras.layers.LSTM(32, kernel_regularizer = L1L2(l1=0.01, l2=0.01), name = 'away_LSTM_1')(away_input)\n",
    "\n",
    "h_a = tf.keras.layers.Concatenate()([home_LSTM_1,away_LSTM_1])\n",
    "#h_a = tf.keras.layers.Dropout(0.234375)(h_a)\n",
    "#Dense1 = tf.keras.layers.Dense(64,'relu',name='Dense1')(h_a)\n",
    "#Dense1 = tf.keras.layers.Dropout(0.234375)(Dense1)\n",
    "#Dense2 = tf.keras.layers.Dense(16,'relu',name='Dense2')(Dense1)\n",
    "#Dense2 = tf.keras.layers.Dropout(0.125)(Dense2)\n",
    "\n",
    "\n",
    "game_input = tf.keras.Input(shape = (5,8), name = 'game_train_input')                                   #input 3\n",
    "game_LSTM_1 = tf.keras.layers.LSTM(32, kernel_regularizer = L1L2(l1=0.001, l2=0.02), name = 'game_LSTM_1')(game_input)\n",
    "\n",
    "\n",
    "h_a_g = tf.keras.layers.Concatenate()([h_a,game_LSTM_1])\n",
    "#Dense3 = tf.keras.layers.Dense(64,'relu',name='Dense3')(h_a_g)\n",
    "#Dense3 = tf.keras.layers.Dropout(0.125)(Dense3)\n",
    "\n",
    "#players\n",
    "player_input = tf.keras.Input(shape = (192), name = 'player_input')  \n",
    "#Dense1 = tf.keras.layers.Dense(64,'relu', kernel_regularizer=L1L2(l1=0.001, l2=0.001),name='Dense1')(player_input)\n",
    "#Dense1 = tf.keras.layers.Dropout(0.2)(Dense1)\n",
    "\n",
    "\n",
    "#final concat\n",
    "\n",
    "h_a_g_p = tf.keras.layers.Concatenate()([h_a_g,player_input])\n",
    "Dense4 = tf.keras.layers.Dense(64,'relu', kernel_regularizer=L1L2(l1=0.001, l2=0.001),name='Dense4')(h_a_g_p)\n",
    "Dense4 = tf.keras.layers.Dropout(0.2)(Dense4)\n",
    "\n",
    "\n",
    "\n",
    "Dense_output = tf.keras.layers.Dense(3, 'softmax', name='output')(Dense4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.Model(inputs=[home_input,away_input,game_input,player_input], outputs=Dense_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(0.0003)\n",
    "loss = SparseCategoricalCrossentropy()\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "model_1.compile(optimizer=opt, loss=loss, metrics = [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x.name for x in model_1.layers])\n",
    "print([x.name for x in LSTM_model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on va chercher les poids du modèle déjà entrainé\n",
    "model_1.layers[2].set_weights(LSTM_model.layers[2].get_weights())\n",
    "model_1.layers[3].set_weights(LSTM_model.layers[3].get_weights())\n",
    "model_1.layers[6].set_weights(LSTM_model.layers[11].get_weights())\n",
    "#model_1.layers[8].set_weights(LSTM_model.layers[8].get_weights())\n",
    "#model_1.layers[9].set_weights(LSTM_model.layers[11].get_weights())\n",
    "#model_1.layers[11].set_weights(LSTM_model.layers[11].get_weights())\n",
    "#model_1.layers[12].set_weights(LSTM_model.layers[13].get_weights())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 1.,\n",
    "                1: 1,\n",
    "                2: 1.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"foot_LSTM_AVGplayers\", entity=\"padda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.init(project=\"foot_LSTM_AVGplayers\", entity=\"padda\")\n",
    "model_1.fit(\n",
    "    train_generator2,\n",
    "    epochs=500,\n",
    "    validation_data=val_generator2,\n",
    "    callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model_1.predict([XH_test, XA_test, XG_test, players_test]).argmax(axis=-1)\n",
    "y_train_pred = model_1.predict([XH_train, XA_train, XG_train, players_train]).argmax(axis=-1)\n",
    "\n",
    "\n",
    "cm_metrics(y_test,y_test_pred, [0,1,2])\n",
    "cm_metrics(y_train,y_train_pred, [0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save('data/models/H_A_G_P_reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_generator))[0][4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "home_input = tf.keras.Input(shape = (10,6) , name = 'home_train_input')                                   #input 1\n",
    "home_LSTM_1 = tf.keras.layers.LSTM(32, kernel_regularizer = L1L2(l1=0.01, l2=0.01), name = 'home_LSTM_1')(home_input)\n",
    "\n",
    "away_input = tf.keras.Input(shape = (10,6), name = 'away_train_input')                                   #input 2\n",
    "away_LSTM_1 = tf.keras.layers.LSTM(32, kernel_regularizer = L1L2(l1=0.01, l2=0.01), name = 'away_LSTM_1')(away_input)\n",
    "\n",
    "h_a = tf.keras.layers.Concatenate()([home_LSTM_1,away_LSTM_1])\n",
    "#h_a = tf.keras.layers.Dropout(0.234375)(h_a)\n",
    "#Dense1 = tf.keras.layers.Dense(64,'relu',name='Dense1')(h_a)\n",
    "#Dense1 = tf.keras.layers.Dropout(0.234375)(Dense1)\n",
    "#Dense2 = tf.keras.layers.Dense(16,'relu',name='Dense2')(Dense1)\n",
    "#Dense2 = tf.keras.layers.Dropout(0.125)(Dense2)\n",
    "\n",
    "\n",
    "game_input = tf.keras.Input(shape = (5,8), name = 'game_train_input')                                   #input 3\n",
    "game_LSTM_1 = tf.keras.layers.LSTM(32, kernel_regularizer = L1L2(l1=0.001, l2=0.02), name = 'game_LSTM_1')(game_input)\n",
    "\n",
    "\n",
    "h_a_g = tf.keras.layers.Concatenate()([h_a,game_LSTM_1])\n",
    "#Dense3 = tf.keras.layers.Dense(64,'relu',name='Dense3')(h_a_g)\n",
    "#Dense3 = tf.keras.layers.Dropout(0.125)(Dense3)\n",
    "\n",
    "#players\n",
    "player_input = tf.keras.Input(shape = (192), name = 'player_input')  \n",
    "Dense1 = tf.keras.layers.Dense(64,'relu', kernel_regularizer=L1L2(l1=0.001, l2=0.001),name='Dense1')(player_input)\n",
    "Dense1 = tf.keras.layers.Dropout(0.2)(Dense1)\n",
    "\n",
    "\n",
    "#best_players\n",
    "best_player_input = tf.keras.Input(shape = (144), name = 'best_player_input')  \n",
    "Dense2 = tf.keras.layers.Dense(64,'relu', kernel_regularizer=L1L2(l1=0.001, l2=0.001),name='Dense2')(best_player_input)\n",
    "Dense2 = tf.keras.layers.Dropout(0.2)(Dense2)\n",
    "\n",
    "\n",
    "#final concat\n",
    "\n",
    "h_a_g_p = tf.keras.layers.Concatenate()([h_a_g, Dense1, Dense2])\n",
    "Dense4 = tf.keras.layers.Dense(128,'relu', kernel_regularizer=L1L2(l1=0.001, l2=0.001),name='Dense4')(h_a_g_p)\n",
    "Dense4 = tf.keras.layers.Dropout(0.2)(Dense4)\n",
    "\n",
    "\n",
    "\n",
    "Dense_output = tf.keras.layers.Dense(3, 'softmax', name='output')(Dense4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Model(inputs=[home_input,away_input,game_input,player_input,best_player_input], outputs=Dense_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(0.0003)\n",
    "loss = SparseCategoricalCrossentropy()\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "model_2.compile(optimizer=opt, loss=loss, metrics = [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x.name for x in model_2.layers])\n",
    "print()\n",
    "print([x.name for x in LSTM_model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.layers[2].set_weights(LSTM_model.layers[2].get_weights())\n",
    "model_2.layers[3].set_weights(LSTM_model.layers[3].get_weights())\n",
    "#model_2.layers[6].set_weights(LSTM_model.layers[6].get_weights())\n",
    "model_2.layers[8].set_weights(LSTM_model.layers[11].get_weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"foot_LSTM_AVGplayers\", entity=\"padda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.fit(\n",
    "    train_generator,\n",
    "    epochs=500,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[WandbCallback()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model_2.predict([XH_test, XA_test, XG_test, players_test, best_test]).argmax(axis=-1)\n",
    "y_train_pred = model_2.predict([XH_train, XA_train, XG_train, players_train, best_train]).argmax(axis=-1)\n",
    "\n",
    "\n",
    "cm_metrics(y_test,y_test_pred, [0,1,2])\n",
    "cm_metrics(y_train,y_train_pred, [0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7487845996c7ba5663e8475bda763caf28d03a7733caf66b680b36d8ed7e8fd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('foot_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
